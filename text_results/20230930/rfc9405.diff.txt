150,152c150,153
<    Tokenization:  The text input is split into individual words or
<       tokens.  This is typically done using a tokenizer, such as the
<       NLTK library in Python.
---
>    Tokenization:
>       The text input is split into individual words or tokens.  This is
>       typically done using a tokenizer, such as the NLTK library in
>       Python.
154,160c155,161
<    Feature extraction:  Features that are indicative of sarcasm are
<       extracted from the tokens.  These features can include linguistic
<       patterns (e.g., the use of exaggeration, irony, or
<       understatement), contextual cues (e.g., the use of quotation marks
<       or emoticons), and sentiment analysis (e.g., detecting a
<       discrepancy between the sentiment of the words and the sentiment
<       of the overall message).
---
>    Feature extraction:
>       Features that are indicative of sarcasm are extracted from the
>       tokens.  These features can include linguistic patterns (e.g., the
>       use of exaggeration, irony, or understatement), contextual cues
>       (e.g., the use of quotation marks or emoticons), and sentiment
>       analysis (e.g., detecting a discrepancy between the sentiment of
>       the words and the sentiment of the overall message).
